<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.336">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-05-09">

<title>Introducing convolutional neural networks</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="ConvolutionalNN_files/libs/clipboard/clipboard.min.js"></script>
<script src="ConvolutionalNN_files/libs/quarto-html/quarto.js"></script>
<script src="ConvolutionalNN_files/libs/quarto-html/popper.min.js"></script>
<script src="ConvolutionalNN_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ConvolutionalNN_files/libs/quarto-html/anchor.min.js"></script>
<link href="ConvolutionalNN_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ConvolutionalNN_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ConvolutionalNN_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ConvolutionalNN_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ConvolutionalNN_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#how-and-what-do-computers-see" id="toc-how-and-what-do-computers-see" class="nav-link active" data-scroll-target="#how-and-what-do-computers-see">How and What do computers see</a></li>
  <li><a href="#convolutional-layer" id="toc-convolutional-layer" class="nav-link" data-scroll-target="#convolutional-layer">Convolutional Layer</a>
  <ul class="collapse">
  <li><a href="#one-layer-of-a-convolutional-neural-network" id="toc-one-layer-of-a-convolutional-neural-network" class="nav-link" data-scroll-target="#one-layer-of-a-convolutional-neural-network">One-layer of a convolutional neural network</a></li>
  <li><a href="#deep-convolutional-network" id="toc-deep-convolutional-network" class="nav-link" data-scroll-target="#deep-convolutional-network">Deep Convolutional Network</a></li>
  </ul></li>
  <li><a href="#pooling-layers" id="toc-pooling-layers" class="nav-link" data-scroll-target="#pooling-layers">Pooling Layers</a>
  <ul class="collapse">
  <li><a href="#average-pooling" id="toc-average-pooling" class="nav-link" data-scroll-target="#average-pooling">Average pooling</a></li>
  </ul></li>
  <li><a href="#fully-connected-layer" id="toc-fully-connected-layer" class="nav-link" data-scroll-target="#fully-connected-layer">Fully Connected Layer</a></li>
  <li><a href="#cnn-definition-in-keras" id="toc-cnn-definition-in-keras" class="nav-link" data-scroll-target="#cnn-definition-in-keras">CNN definition in Keras</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="ConvolutionalNN.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introducing convolutional neural networks</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-contents">
             <p>Esteban Vegas </p>
             <p>Alex Sanchez </p>
             <p>Ferran Reverter </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 9, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="how-and-what-do-computers-see" class="level1">
<h1>How and What do computers see</h1>
<p>Computer vision is an exciting field, which has evolved quickly thanks to deep learning. Researchers in this area have been experimenting many neural-network architectures and algorithms, which have influenced other fields as well. In computer vision, images are the training data of a network, and the input features are the pixels of an image. These features can get really big. For example, when dealing with a 1megapixel image, the total number of features in that picture is 3 million (<span class="math inline">\(=1000\times 1000 \times 3\)</span> color channels). Then imagine passing this through a neural network with just 1000 hidden units, and we end up with some weights of 3 billion parameters! These numbers are too big to be managed, but, luckily, we have the perfect solution: Convolutional neural networks (CNN), see Figure 1.</p>
<p>“<code>{r, fig.align='center', out.width='100%', fig.cap=''}\nknitr::include_graphics(\"![Convolutional Neural Network](images/cnn.png{width=60%, fig.pos=\"h\"}\")\n</code>”</p>
<p>There are 3 main types of layers in a convolutional network:</p>
<ul>
<li>Convolution (CONV)</li>
<li>Pooling (POOL)</li>
<li>Fully connected (FC)</li>
</ul>
</section>
<section id="convolutional-layer" class="level1">
<h1>Convolutional Layer</h1>
<p>A “convolution” is one of the building blocks of the Convolutional network. The primary purpose of a “convolution” in the case of a CNN is to extract features from the input image (Fig. 2).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/abs_cat.png" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Spatial hierarchy of visual modules</figcaption>
</figure>
</div>
<p>Every image can be represented as a matrix of pixel values. An image from a standard digital camera will have three channels: red, green and blue. You can imagine those as three 2d-matrices stacked over each other (one for each color), each having pixel values in the range 0 to 255.</p>
<p>Applying a convolution to an image is like running a filter of a certain dimension and sliding it on top of the image. That operation is translated into an element-wise multiplication between the two matrices and finally an addition of the multiplication outputs. The final integer of this computation forms a single element of the output matrix. Let’s review this via an example, where we want to apply a filter (kernel) to detect vertical and horizontal edges from a 2D original image (Fig. 3).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cnn_conv.png" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Convolution filter</figcaption>
</figure>
</div>
<p>In this example, we used a value of a stride equal to 1, meaning the filter moves horizontally and vertically by one pixel (see Figure 4).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_1.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Sliding the filter</figcaption>
</figure>
</div>
<p>In this example the values of the filter were already decided in the convolution. <strong>The goal of a convolutional neural network is to learn the values in the filters</strong>. We treat them as <strong>weights</strong> of the neural network, which the network learns from data using backpropagation.</p>
<p>You might be wondering how to calculate the output size, based on the filter dimensions and the way we slide it though the image. We will get to the formula, but first We want to introduce a bit of terminology.</p>
<p>You saw in the earlier example how the filter moved with a stride of 1 and covered the whole image from edge to edge. This is what it’s called a <strong>valid</strong> convolution since the filter stays within the borders of the image.</p>
<p>However, one problem quickly arises. When moving the filter this way we see that the pixels on the edges are “touched” less by the filter than the pixels within the image. That means we are throwing away some information related to those positions. Furthermore, the output image is shrinking on every convolution, which could be intentional, but if the input image is small, we quickly shrink it too fast.</p>
<p>A solution to those setbacks is the use of <strong>padding</strong>. Before we apply a convolution, we pad the image with zeros all around its border to allow the filter to slide on top and maintain the output size equal to the input. The result of padding in the previous example will be (Figure 5).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_2.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Padding</figcaption>
</figure>
</div>
<p>Padding will result in a <strong>same</strong> convolution. We talked about <strong>stride</strong>, which is essentially how many pixels the filter shifts over the original image. Great, so now We can introduce the formula to quickly calculate the output size, knowing the filter size (<span class="math inline">\(f\)</span>), stride (<span class="math inline">\(s\)</span>), pad (<span class="math inline">\(p\)</span>), and input size (<span class="math inline">\(n\)</span>):</p>
<p>Output size</p>
<p><span class="math display">\[
\Big(\frac{n+2p-f}{s}+1\Big)\times \Big(\frac{n+2p-f}{s}+1\Big)
\]</span></p>
<p>Keep in mind that the filter size is usually an odd value, and if the fraction above is not an integer you should round it down.</p>
<p>The previous example was on a 2D matrix, but we mentioned earlier that images are composed of three channels (R-red, G-green, B-blue). Therefore the input is a volume, a stack of three matrices, which forms a depth identified by the number of channels. If we apply only one filter the result would be (Figure 6), where the cube filter of 27 parameters now slides on top of the cube of the input image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_3.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Output</figcaption>
</figure>
</div>
<p>So far we have only applied one filter at a time, but we can apply multiple filters to detect several different features. This is what brings us to the crucial concept for building convolutional neural networks. Now each filter brings us its own output We can stack them all together and create an output volume, such as, see Figures 7, 8 and 9.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_4.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Output volume</figcaption>
</figure>
</div>
<p>Therefore, in general terms we have:</p>
<p>Input: <span class="math inline">\((n \times n \times n_c)\)</span></p>
<p>Filter: <span class="math inline">\((f \times f \times n_c)\)</span></p>
<p>Output: <span class="math inline">\(\Big(\big(\frac{n+2p-f}{s}+1\big)\times \big(\frac{n+2p-f}{s}+1\big)\times n'_c\Big)\)</span></p>
<p>(with <span class="math inline">\(n'_c\)</span> as the number of filters, which are detecting different features)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cnn_filter_1.png" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Representing a full color RGB image as a volume and applying a convolutional filter</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cnn_filter_2.png" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">A three-dimensional visualization of a convolutional layer, where each filter corresponds to a slice in the resuting output volumen.</figcaption>
</figure>
</div>
<section id="one-layer-of-a-convolutional-neural-network" class="level2">
<h2 class="anchored" data-anchor-id="one-layer-of-a-convolutional-neural-network">One-layer of a convolutional neural network</h2>
<p>The final step that takes us to a convolutional neural layer is to add the bias and a non-linear function (Figure 10).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_5.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Bias term</figcaption>
</figure>
</div>
<p>Remember that the parameters involved in one layer are independent of the input size image. So let’s consider, for example, that we have <span class="math inline">\(10\)</span> filters that are of size <span class="math inline">\(3\times 3\times 3\)</span> in one layer of a neural network. Each filter has <span class="math inline">\(27\)</span> <span class="math inline">\((=3\times 3\times 3) + 1\)</span> bias <span class="math inline">\(=&gt; 28\)</span> parameters. Therefore, the total amount of parameters in the layer is 280 (<span class="math inline">\(10\times 28\)</span>).</p>
<p>This means that all the neurons in the first hidden layer detect exactly the same feature, just at different locations in the input image. To see why this makes sense, suppose the weights and bias are such that the hidden neuron can pick out, say, a vertical edge in a particular local receptive field. That ability is also likely to be useful at other places in the image. And so it is useful to apply the same feature detector everywhere in the image. To put it in slightly more abstract terms, convolutional networks are well adapted to the translation invariance of images: move a picture of a cat (say) a little ways, and it’s still an image of a cat.</p>
<p>For this reason, we sometimes call the map from the input layer to the hidden layer a feature map. We call the weights defining the feature map the <strong>shared weights</strong>. And we call the bias defining the feature map in this way the <strong>shared bias</strong>. The shared weights and bias are often said to define a kernel or filter (Figures 11 and 12, also link to https://pathmind.com/wiki/convolutional-network).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_x1.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Convolution process</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_x2.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Convolution process</figcaption>
</figure>
</div>
</section>
<section id="deep-convolutional-network" class="level2">
<h2 class="anchored" data-anchor-id="deep-convolutional-network">Deep Convolutional Network</h2>
<p>We are now ready to build a complete deep convolutional neural network. The following architecture depicts a simple example of that (Figure 13)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_6.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Stacked convolution layers</figcaption>
</figure>
</div>
</section>
</section>
<section id="pooling-layers" class="level1">
<h1>Pooling Layers</h1>
<p>There are two types of pooling layers: max and average pooling. Max pooling We define a spatial neighborhood (a filter), and as we slide it through the input, we take the largest element within the region covered by the filter.</p>
<p>We can think of max-pooling as a way for the network to ask whether a given feature is found anywhere in a region of the image. It then throws away the exact positional information. The intuition is that once a feature has been found, its exact location isn’t as important as its rough location relative to other features. A big benefit is that there are many fewer pooled features, and so this helps reduce the number of parameters needed in later layers (Figure 14).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_7.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Max-pooling</figcaption>
</figure>
</div>
<section id="average-pooling" class="level2">
<h2 class="anchored" data-anchor-id="average-pooling">Average pooling</h2>
<p>As the name suggests, it retains the average of the values encountered within the filter. One thing worth noting is the fact that a pooling layer does not have any parameters to learn. Of course, we have hyper-parameters to select, the filter size and the stride (it’s common not to use any padding).</p>
</section>
</section>
<section id="fully-connected-layer" class="level1">
<h1>Fully Connected Layer</h1>
<p>A fully connected layer acts like a “standard” single neural network layer, where you have a weight matrix W and bias b. We can see its application in the following example of a Convolutional Neural Network. This network is inspired by the LeNet-5 network (Figure 15).</p>
<p>It’s common that, as we go deeper into the network, the sizes (nh, nw) decrease, while the number of channels (nc) increases.</p>
<p>Another common pattern you can see in neural networks is to have CONV layers, one or more, followed by a POOL layer, and then again one or more CONV layers followed by a POOL layer and, at the end, a few FC layers followed by a Softmax.</p>
<p>When choosing the right hyper-parameters (f, s, p, ..), look at the literature and choose an architecture that was successfully used and that can apply to your application. There are several “classic” networks, such as LeNet, AlexNet, VGG,</p>
<p>These networks are normally used in transfer learning, where we can use the weights coming from the existing trained network and then replace the output unit, since training such a big network from scratch would require a long time otherwise.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/img_8.PNG" class="img-fluid figure-img" data-fig.pos="h"></p>
<figcaption class="figure-caption">Convolution network scheme</figcaption>
</figure>
</div>
</section>
<section id="cnn-definition-in-keras" class="level1">
<h1>CNN definition in Keras</h1>
<div class="cell" data-hash="ConvolutionalNN_cache/html/unnamed-chunk-1_880792caf752fd5d75d71dfdb9e0061b">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># small convnet</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">%&gt;%</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">6</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">strides =</span> <span class="dv">1</span>, <span class="at">padding =</span> <span class="st">"valid"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">activation =</span> <span class="st">"relu"</span>,<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_conv_2d</span>(<span class="at">filters =</span> <span class="dv">16</span>, <span class="at">kernel_size =</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">5</span>), <span class="at">strides =</span> <span class="dv">1</span>, <span class="at">padding =</span> <span class="st">"valid"</span>,</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_max_pooling_2d</span>(<span class="at">pool_size =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>() <span class="sc">%&gt;%</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">120</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">84</span>, <span class="at">activation =</span> <span class="st">"relu"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>, <span class="at">activation =</span> <span class="st">"softmax"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-hash="ConvolutionalNN_cache/html/unnamed-chunk-2_2560087822607f6f87985723e8582972">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>