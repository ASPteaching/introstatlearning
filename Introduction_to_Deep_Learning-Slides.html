<!DOCTYPE html>
<html lang="en"><head>
<script src="Introduction_to_Deep_Learning-Slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/popper.min.js"></script>
<script src="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="Introduction_to_Deep_Learning-Slides_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.336">

  <meta name="author" content="A. Sanchez, F. Reverter and E. Vegas">
  <title>Introduction to ANN and Deep Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link rel="stylesheet" href="css4CU.css">
  <link href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Introduction to ANN and Deep Learning</h1>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
A. Sanchez, F. Reverter and E. Vegas 
</div>
</div>
</div>

</section>
<section>
<section id="overview-of-deep-learning" class="title-slide slide level1 center">
<h1>Overview of Deep Learning</h1>

</section>
<section id="historical-background-1" class="slide level2">
<h2>Historical Background (1)</h2>
<ul>
<li><p>Today, in April 2023, our world is convulsed by the explosion of Artificial Intelligence.</p></li>
<li><p>It has probably been in the last months (weeks), since ChatGPT has arrived, that everybody has an opinion, or a fear on the topic.</p></li>
</ul>

<img data-src="https://bernardmarr.com/wp-content/uploads/2022/04/The-Dangers-Of-Not-Aligning-Artificial-Intelligence-With-Human-Values.jpg" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="historical-background-2" class="slide level2">
<h2>Historical Background (2)</h2>
<ul>
<li><p>AI use statistical learning methods, such as machine learning algorithms, to make predictions based on large amounts of data.</p></li>
<li><p>Prediction is a fundamental capability of AI and is used in a wide range of applications.</p></li>
<li><p>However, it is important to keep in mind that AI has far-reaching implications beyond its predictive capabilities, including ethical, social or technological.</p></li>
</ul>
</section>
<section id="deep-learning" class="slide level2">
<h2>Deep learning</h2>
<ul>
<li><p>Deep learning is a successful AI model which has powered many application such as <em>self-driving cars, voice assistants, and medical diagnosis systems</em>.</p></li>
<li><p>Essentially, deep learning extends the basic principles of artificial neural networks by</p>
<ul>
<li>Adding complex architectures and algorithms and</li>
<li>At the same time becoming more automatic</li>
</ul></li>
<li><p>We won’t delve into the history of ANN, but a quick look at it may help fully grasp its current capabilities.</p></li>
</ul>
</section>
<section id="the-early-history-of-ai-1" class="slide level2">
<h2>The early history of AI (1)</h2>

<img data-src="images/AIHistory1.jpg" style="width:100.0%" class="r-stretch quarto-figure-center"><p class="caption">A Brief History of AI from 1940s till Today</p><ul>
<li>The origins of AI, and as such of DL can be traced almost one century backwards;</li>
<li><a href="https://nerdyelectronics.com/a-quick-history-of-ai-ml-and-dl/" id="AIHistory">A Quick History of AI, ML and DL</a></li>
</ul>
</section>
<section id="milestones-in-the-history-of-dl" class="slide level2">
<h2>Milestones in the history of DL</h2>
<p>We can see several hints worth to account for:</p>
<ul>
<li><p>The <strong>Perceptron</strong> and the first <strong>Artificial Neural Network</strong> where the basic building block was introduced.</p></li>
<li><p>The <strong>Multilayered perceptron</strong> and back-propagation where complex architectures were suggested to improve the capabilities.</p></li>
<li><p><strong>Deep Neural Networks</strong>, with many hidden layers, and auto-tunability capabilities.</p></li>
</ul>
</section>
<section id="from-artificial-neural-networks-to-deep-learning" class="slide level2">
<h2>From Artificial Neural Networks to Deep learning</h2>
<p><img data-src="images/WhyDLNow.png" style="width:100.0%" data-fig-align="center" alt="Why Deep Learning Now?"> Source: Alex Amini’s ‘MIT Introduction to Deep Learning’ course (introtodeeplearning.com)</p>
</section>
<section id="success-stories" class="slide level2">
<h2>Success stories</h2>
<p>Success stories such as</p>
<ul>
<li><p>the development of self-driving cars,</p></li>
<li><p>the use of AI in medical diagnosis, and</p></li>
<li><p>the creation of personalized recommendations in online shopping</p></li>
</ul>
<p>have also contributed to the widespread adoption of AI.</p>
</section>
<section id="ai-ml-dl" class="slide level2">
<h2>AI, ML, DL …</h2>

<img data-src="images/AI-ML-DL-1.jpg" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="ai-ml-dl-1" class="slide level2">
<h2>AI, ML, DL …</h2>
<ul>
<li><p>Artificial intelligence: Ability of a computer to perform tasks commonly associated with intelligent beings.</p></li>
<li><p>Machine learning: study of algorithms that learn from examples and experience instead of relying on hard-coded rules and make predictions on new data</p></li>
<li><p>Deep learning: sub field of ML focusing on learning data representations as successive successive layers of increasingly meaningful representations.</p></li>
</ul>
</section>
<section id="machine-vs-deep-learning" class="slide level2">
<h2>Machine vs Deep Learning</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>DNN: feature extraction and classification without (or with much les) human intervention.</li>
<li>DNN improves with data availability, without seemingly reaching plateaus.</li>
</ul>
</div><div class="column" style="width:60%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/ML_vs_DL-2.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="size-does-matter" class="slide level2">
<h2>Size does matter!</h2>

<img data-src="images/PerformanceVsAmountOfData.png" style="width:100.0%" class="r-stretch quarto-figure-center"><p class="caption">An illustration of the performance comparison between deep learning (DL) and other machine learning (ML) algorithms, where DL modeling from large amounts of data can increase the performance</p></section>
<section id="the-impact-of-deep-learning" class="slide level2 smaller">
<h2>The impact of Deep learning</h2>
<ul>
<li><p>Near-human-level image classification</p></li>
<li><p>Near-human-level speech transcription</p></li>
<li><p>Near-human-level handwriting transcription</p></li>
<li><p>Dramatically improved machine translation</p></li>
<li><p>Dramatically improved text-to-speech conversion</p></li>
<li><p>Digital assistants such as Google Assistant and Amazon Alexa</p></li>
<li><p>Near-human-level autonomous driving</p></li>
<li><p>Improved ad targeting, as used by Google, Baidu, or Bing</p></li>
<li><p>Improved search results on the web</p></li>
<li><p>Ability to answer natural language questions</p></li>
<li><p>Superhuman Go playing</p></li>
</ul>
</section>
<section id="not-all-that-glitters-is-gold" class="slide level2">
<h2>Not all that glitters is gold …</h2>
<ul>
<li><p>According to F. Chollet, the developer of Keras,</p>
<ul>
<li>“<em>we shouldn’t believe the short-term hype, but should believe in the long-term vision</em>.</li>
<li><em>It may take a while for AI to be deployed to its true potential—a potential the full extent of which no one has yet dared to dream</em></li>
<li><em>but AI is coming, and it will transform our world in a fantastic way</em>”.</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="artificial-neural-networks" class="title-slide slide level1 center">
<h1>Artificial Neural Networks</h1>

</section>
<section id="the-perceptron-the-building-block" class="slide level2">
<h2>The perceptron, the building block</h2>
<ul>
<li><p>The perceptron, was introduced in the 50’s (one version of the perceptron at least), as a mathematical model that might emulate a neuron.</p></li>
<li><p>The idea was <em>trying</em> <em>to produce a model that, given some inputs, and an appropriate set of examples, learn to produce the desired output</em>.</p></li>
</ul>
</section>
<section id="mc-culloughs-neuron" class="slide level2">
<h2>Mc Cullough’s neuron</h2>
<ul>
<li>The first computational model of a neuron was proposed by Warren MuCulloch (neuroscientist) and Walter Pitts (logician) in 1943.</li>
</ul>

<img data-src="images/MacCulloghPitts-Neuron.png" style="width:93.0%" class="r-stretch quarto-figure-center"></section>
<section id="mc-culloughs-neuron-1" class="slide level2">
<h2>Mc Cullough’s neuron</h2>
<ul>
<li>It may be divided into 2 parts.
<ul>
<li>The first part, <span class="math inline">\(g\)</span>,takes an input (ahem dendrite ahem),</li>
<li>It performs an aggregation and</li>
<li>based on the aggregated value the second part, <span class="math inline">\(f\)</span>, makes a decision.</li>
</ul></li>
</ul>
<p>See <a href="https://towardsdatascience.com/mcculloch-pitts-model-5fdf65ac5dd1">the source of this picture</a> for an illustration on how this can be used to emulate logical operations such as AND, OR or NOT, but not XOR.</p>
</section>
<section id="limitations" class="slide level2">
<h2>Limitations</h2>
<p>This first attempt to emulate neurons succeeded but with limitations:</p>
<ul>
<li><p>What about non-Boolean (say, real) inputs?</p></li>
<li><p>What if all inputs are not equal?</p></li>
<li><p>What if we want to assign more importance to some inputs?</p></li>
<li><p>What about functions which are not linearly separable? Say XOR function</p></li>
</ul>
</section>
<section id="overcoming-the-limitations" class="slide level2">
<h2>Overcoming the limitations</h2>
<ul>
<li><p>To overcome these limitations Frank Rosenblatt, proposed the classical perception model, the <em>artificial neuron</em>, in 1958.</p></li>
<li><p>It is more generalized computational model than the McCullough-Pitts neuron where weights and thresholds can be learnt over time.</p></li>
<li><p>Rosenblatt’s perceptron is very similar to an M-P neuron but</p>
<ul>
<li>It takes a weighted sum of the inputs and</li>
<li>It sets the output as one only when the sum is more than an arbitrary threshold (<strong><em>theta</em></strong>).</li>
</ul></li>
</ul>
</section>
<section id="rosenblatts-perceptron" class="slide level2">
<h2>Rosenblatt’s perceptron</h2>

<img data-src="images/RosenblattPerceptron1.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="rosenblatts-perceptron-1" class="slide level2">
<h2>Rosenblatt’s perceptron (1)</h2>
<ul>
<li>Instead of hand coding the thresholding parameter <span class="math inline">\(\theta\)</span>,</li>
<li>It is added as one of the inputs, with the weight <span class="math inline">\(w_0=-\theta\)</span>.</li>
</ul>

<img data-src="images/RosenblattPerceptron2.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="comparison-between-the-two" class="slide level2">
<h2>Comparison between the two</h2>

<img data-src="images/McCullaughVSRosenblattPerceptron.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="comparison-between-the-two-1" class="slide level2">
<h2>Comparison between the two</h2>
<ul>
<li><p>This is an improvement because</p>
<ul>
<li>both, weights and threshold, can be learned and</li>
<li>the inputs can be real values</li>
</ul></li>
<li><p>But there is still a drawback in that a single perceptron can only be used to implement linearly separable functions.</p></li>
<li><p>Artificial Neural Networks improve on this by introducing <em>Activation Functions</em></p></li>
</ul>
</section>
<section id="activation-in-biological-neurons" class="slide level2">
<h2>Activation in biological neurons</h2>
<ul>
<li>Biological neurons are specialized cells in the CNS that transmit electrical and chemical signals to communicate with each other.</li>
<li>The neuron’s activation is based on the release of neurotransmitters, chemical substances that transmit signals between nerve cells.
<ul>
<li>When the signal reaching the neuron exceeds a certain threshold, the neuron releases neurotransmitters to continue the communication process.</li>
</ul></li>
</ul>
</section>
<section id="activation-functions-in-an" class="slide level2">
<h2>Activation functions in AN</h2>
<ul>
<li>Analogously, <em>activation functions</em> in AN are functions to decide if the AN it is activated or not.</li>
<li>In AN, the activation function is a mathematical function applied to the neuron’s input to produce an output.
<ul>
<li>In practice it extends to complicated functions that can learn complex patterns in the data.</li>
<li>Activation functions can incorporate non-linearity, improving over linear classifiers.</li>
</ul></li>
</ul>
</section>
<section id="activation-function" class="slide level2">
<h2>Activation function</h2>

<img data-src="images/ActivationFunction0.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="artificial-neuron" class="slide level2">
<h2>Artificial Neuron</h2>
<p>With all these ideas in mind we can now define an Artificial Neuron as a <em>computational unit</em> that :</p>
<ul>
<li><p>takes as input <span class="math inline">\(x=(x_0,x_1,x_2,x_3)\)</span> (<span class="math inline">\(x_0\)</span> = +1, called bias),</p></li>
<li><p>outputs <span class="math inline">\(h_{\theta}(x) = f(\theta^\intercal x) = f(\sum_i \theta_ix_i)\)</span>,</p></li>
<li><p>where <span class="math inline">\(f:\mathbb{R}\mapsto \mathbb{R}\)</span> is called the <strong>activation function</strong>.</p></li>
</ul>
</section>
<section id="activation-functions" class="slide level2">
<h2>Activation functions</h2>
<ul>
<li><p>Goal of activation function is to provide the neuron with <em>the capability of producing the required outputs</em>.</p></li>
<li><p>Flexible enough to produce</p>
<ul>
<li>Either linear or non-linear transformations.</li>
<li>Output in the desired range ([0,1], {-1,1}, <span class="math inline">\(\mathbb{R}^+\)</span>…)</li>
</ul></li>
<li><p>Usually chosen from a (small) set of possibilities.</p>
<ul>
<li>Sigmoid function:</li>
<li>Hyperbolic tangent, or <code>tanh</code>, function</li>
<li>ReLU</li>
</ul></li>
</ul>
</section>
<section id="the-sigmoid-function" class="slide level2 smaller">
<h2>The sigmoid function</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><span class="math display">\[
f(z)=\frac{1}{1+e^{-z}}
\]</span></p>
<ul>
<li><p>Output real values <span class="math inline">\(\in (0,1)\)</span>.</p></li>
<li><p>Natural interpretations as <em>probability</em> of an event</p></li>
<li><p><em>vanishing gradient</em> problem</p></li>
<li><p>Its derivative is: <span class="math inline">\(f'(z)=f(z)(1-f(z))\)</span>.</p></li>
</ul>
</div><div class="column" style="width:60%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/SigmoidFunction.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="the-hyperbolic-tangent" class="slide level2 smaller">
<h2>the hyperbolic tangent</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p>Also called <code>tanh</code>, function:</p>
<p><span class="math display">\[
f(z)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}
\]</span></p>
<ul>
<li><p>outputs are zero-centered and bounded in −1,1</p></li>
<li><p>scaled and shifted Sigmoid</p></li>
<li><p>stronger gradient but still has vanishing gradient problem</p></li>
<li><p>Its derivative is <span class="math inline">\(f'(z)=1-(f(z))^2\)</span>.</p></li>
</ul>
</div><div class="column" style="width:60%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/TanhFunction.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="the-relu" class="slide level2 smaller">
<h2>The ReLU</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li><p><em>rectified linear unit</em>: <span class="math inline">\(f(z)=\max\{0,z\}\)</span>.</p></li>
<li><p>Close to a linear: piece-wise <em>linear</em> function with two linear pieces.</p></li>
<li><p>Outputs are in %(0,)$ , thus not bounded</p></li>
<li><p>Half rectified: activation threshold at 0</p></li>
<li><p>No vanishing gradient problem</p></li>
</ul>
</div><div class="column" style="width:60%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/ReLUFunction.png" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="more-activation-functions" class="slide level2">
<h2>More activation functions</h2>
<p><img data-src="images/ActivationFunctions.png" style="width:100.0%">.</p>
</section>
<section id="putting-it-all-together" class="slide level2">
<h2>Putting it all together</h2>

<img data-src="images/ArtificialNeuron.png" style="width:100.0%" class="r-stretch quarto-figure-center"><p><span class="math inline">\(\Sigma=\left\langle w_{j}, x\right\rangle+ b_{j}\)</span></p>
</section>
<section id="multilayer-perceptrons" class="slide level2 smaller">
<h2>Multilayer perceptrons</h2>
<ul>
<li>A Multilayer Perceptron or Artificial Neural Network (ANN) is a computational model that mimics the structure and function of the human brain.</li>
<li>It is composed of interconnected nodes, called neurons, that are organized into layers.</li>
<li>Neurons in each layer are connected to neurons in the next layer, forming a directed graph-like structure.</li>
<li>The first layer (input layer) receives input data.</li>
<li>Last layer produces the final prediction</li>
<li>Intermediate (hidden) layers perform intermediate calculations.</li>
</ul>
</section>
<section id="an-artificial-neural-network" class="slide level2">
<h2>An Artificial Neural network</h2>

<img data-src="images/MultiLayer1.png" style="width:100.0%" class="r-stretch quarto-figure-center"></section>
<section id="the-architecture-of-ann" class="slide level2">
<h2>The architecture of ANN</h2>
<ul>
<li><p>Multilayers perceptrons have a basic architecture:</p>
<ul>
<li>each unit (or neuron) of a layer is linked to all the units of the next layer</li>
<li>but has no link with the neurons of the same layer.</li>
</ul></li>
<li><p>This basic architecture can changes in many possible ways</p>
<ul>
<li>There may be links between neurons in same layer,</li>
<li>Missing links between two layers …</li>
</ul></li>
</ul>
</section>
<section id="the-architecture-of-an-ann" class="slide level2">
<h2>The architecture of an ANN</h2>
<ul>
<li><p>The architecture of a multilayer perceptron is defined by:</p>
<ul>
<li>The number of hidden layers and</li>
<li>The number of neurons in each layer</li>
</ul></li>
<li><p>Activation functions are important in the definition of the ANN, but not relevant for the architecture.</p></li>
</ul>
</section>
<section id="activation-functions-for-ann-1" class="slide level2">
<h2>Activation functions for ANN (1)</h2>
<ul>
<li>For the output layer, the activation function is generally different from the one used on the hidden layers.
<ul>
<li>For <strong>regression</strong>, we apply no activation function on the output layer.</li>
<li>For <strong>binary</strong> classification, where output is a prediction of <span class="math inline">\(\mathbb{P}(Y=1 /X) \in [0,1]\)</span>
<ul>
<li>The <em>sigmoid</em> activation function is used.</li>
</ul></li>
<li>For <strong>multi-class classification</strong>, where there is one neuron per class giving a prediction of <span class="math inline">\(\mathbb{P}(Y=i / X)\)</span>.
<ul>
<li>The soft-max activation function is common</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="the-soft-max-activation-function" class="slide level2">
<h2>The soft-max activation function</h2>
<p><span class="math display">\[
\operatorname{softmax}(z)_{i}=\frac{\exp \left(z_{i}\right)}{\sum_{j} \exp \left(z_{j}\right)}
\]</span></p>
</section></section>
<section>
<section id="an-example" class="title-slide slide level1 center">
<h1>An example</h1>

</section>
<section id="a-predictive-ann" class="slide level2">
<h2>A predictive ANN</h2>
<p>We use the <code>neuralnet</code> package to build a simple neural network to predict if a type of stock pays dividends or not.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">require</span>(neuralnet)) </span>
<span id="cb1-2"><a href="#cb1-2"></a>  <span class="fu">install.packages</span>(<span class="st">"neuralnet"</span>, <span class="at">dep=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-for-the-example" class="slide level2">
<h2>Data for the example</h2>
<p>And use the <code>dividendinfo.csv</code> dataset from <a href="https://github.com/MGCodesandStats/datasets" class="uri">https://github.com/MGCodesandStats/datasets</a></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>mydata <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"https://raw.githubusercontent.com/MGCodesandStats/datasets/master/dividendinfo.csv"</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="fu">str</span>(mydata)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'data.frame':   200 obs. of  6 variables:
 $ dividend       : int  0 1 1 0 1 1 1 0 1 1 ...
 $ fcfps          : num  2.75 4.96 2.78 0.43 2.94 3.9 1.09 2.32 2.5 4.46 ...
 $ earnings_growth: num  -19.25 0.83 1.09 12.97 2.44 ...
 $ de             : num  1.11 1.09 0.19 1.7 1.83 0.46 2.32 3.34 3.15 3.33 ...
 $ mcap           : int  545 630 562 388 684 621 656 351 658 330 ...
 $ current_ratio  : num  0.924 1.469 1.976 1.942 2.487 ...</code></pre>
</div>
</div>
</section>
<section id="data-pre-processing" class="slide level2">
<h2>Data pre-processing</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>normalize <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span class="fu">return</span> ((x <span class="sc">-</span> <span class="fu">min</span>(x)) <span class="sc">/</span> (<span class="fu">max</span>(x) <span class="sc">-</span> <span class="fu">min</span>(x)))</span>
<span id="cb4-3"><a href="#cb4-3"></a>}</span>
<span id="cb4-4"><a href="#cb4-4"></a>normData <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">lapply</span>(mydata, normalize))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="test-and-training-sets" class="slide level2">
<h2>Test and training sets</h2>
<p>Finally we break our data in a test and a training set:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>perc2Train <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">/</span><span class="dv">3</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>ssize <span class="ot">&lt;-</span> <span class="fu">nrow</span>(normData)</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a>data_rows <span class="ot">&lt;-</span> <span class="fu">floor</span>(perc2Train <span class="sc">*</span>ssize)</span>
<span id="cb5-5"><a href="#cb5-5"></a>train_indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>ssize), data_rows)</span>
<span id="cb5-6"><a href="#cb5-6"></a>trainset <span class="ot">&lt;-</span> normData[train_indices,]</span>
<span id="cb5-7"><a href="#cb5-7"></a>testset <span class="ot">&lt;-</span> normData[<span class="sc">-</span>train_indices,]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training-a-neural-network" class="slide level2">
<h2>Training a neural network</h2>
<p>We train a simple NN with two hidden layers, with 4 and 2 neurons respectively.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">#Neural Network</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="fu">library</span>(neuralnet)</span>
<span id="cb6-3"><a href="#cb6-3"></a>nn <span class="ot">&lt;-</span> <span class="fu">neuralnet</span>(dividend <span class="sc">~</span> fcfps <span class="sc">+</span> earnings_growth <span class="sc">+</span> de <span class="sc">+</span> mcap <span class="sc">+</span> current_ratio, </span>
<span id="cb6-4"><a href="#cb6-4"></a>                <span class="at">data=</span>trainset, </span>
<span id="cb6-5"><a href="#cb6-5"></a>                <span class="at">hidden=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>), </span>
<span id="cb6-6"><a href="#cb6-6"></a>                <span class="at">linear.output=</span><span class="cn">FALSE</span>, </span>
<span id="cb6-7"><a href="#cb6-7"></a>                <span class="at">threshold=</span><span class="fl">0.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="network-plot" class="slide level2">
<h2>Network plot</h2>
<p>The output of the procedure is a neural network with estimated weights</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="fu">plot</span>(nn, <span class="at">rep =</span> <span class="st">"best"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="Introduction_to_Deep_Learning-Slides_files/figure-revealjs/unnamed-chunk-14-1.png" width="960" class="r-stretch"></section>
<section id="predictions" class="slide level2">
<h2>Predictions</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a>temp_test <span class="ot">&lt;-</span> <span class="fu">subset</span>(testset, <span class="at">select =</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>                      <span class="fu">c</span>(<span class="st">"fcfps"</span>,<span class="st">"earnings_growth"</span>, </span>
<span id="cb8-3"><a href="#cb8-3"></a>                        <span class="st">"de"</span>, <span class="st">"mcap"</span>, <span class="st">"current_ratio"</span>))</span>
<span id="cb8-4"><a href="#cb8-4"></a>nn.results <span class="ot">&lt;-</span> <span class="fu">compute</span>(nn, temp_test)</span>
<span id="cb8-5"><a href="#cb8-5"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">actual =</span> </span>
<span id="cb8-6"><a href="#cb8-6"></a>                  testset<span class="sc">$</span>dividend, </span>
<span id="cb8-7"><a href="#cb8-7"></a>                  <span class="at">prediction =</span> nn.results<span class="sc">$</span>net.result)</span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="fu">head</span>(results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   actual   prediction
9       1 0.9919213885
19      1 0.9769206123
22      0 0.0002187144
26      0 0.6093330933
27      1 0.7454164893
29      1 0.9515431416</code></pre>
</div>
</div>
</section>
<section id="model-evaluation" class="slide level2">
<h2>Model evaluation</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>roundedresults<span class="ot">&lt;-</span><span class="fu">sapply</span>(results,round,<span class="at">digits=</span><span class="dv">0</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a>roundedresultsdf<span class="ot">=</span><span class="fu">data.frame</span>(roundedresults)</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="fu">attach</span>(roundedresultsdf)</span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="fu">table</span>(actual,prediction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      prediction
actual  0  1
     0 33  3
     1  4 27</code></pre>
</div>
</div>
</section></section>
<section>
<section id="some-mathematics-behind-ann" class="title-slide slide level1 center">
<h1>Some mathematics behind ANN</h1>

</section>
<section id="training-an-ann" class="slide level2 smaller">
<h2>Training an ANN</h2>
<ul>
<li><p>An ANN is a predictive model whose properties and behaviour can be mathematically characterized.</p></li>
<li><p>In practice this means:</p>
<ul>
<li>The ANN acts by composing a series of linear and non-linear (activation) functions.</li>
<li>These are characterized by their <em>weights</em> and <em>biases</em>, that need to be <em>learnt</em> .</li>
</ul></li>
<li><p><em>Training</em> the network is done by</p>
<ul>
<li>Selecting an appropriate (convex) loss function,</li>
<li>Finding those weights that minimize a the total <em>cost</em> function (avg loss).</li>
</ul></li>
</ul>
</section>
<section id="the-tools-for-training" class="slide level2">
<h2>The tools for training</h2>
<ul>
<li><p>Training an ANN is usually done using some iterative optimization procedure such as <em>Gradient Descent</em>.</p></li>
<li><p>This requires evaluating derivatives in a huge number of points.</p>
<ul>
<li>Such high number may be reduced by <em>Stochastic Gradient Descent</em>.</li>
<li>The evaluation of derivatives is simplified thanks to <em>Backpropagation</em>.</li>
</ul></li>
</ul>
</section>
<section id="a-guiding-example" class="slide level2">
<h2>A guiding example</h2>
<p>Consider a toy ANN to illustrate the concepts</p>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li>Input layer with 3 input units (plus bias unit),</li>
<li>1 hidden layer with 3 hidden units,</li>
<li>Output layer with 1 output unit.</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/nn.jpg" style="width:100.0%"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="a-logistic-regression-ann" class="slide level2">
<h2>A logistic regression ANN</h2>
<ul>
<li><p>From input layer to layer 2: A non-linear transformation yields new set of complex features.</p></li>
<li><p>From layer 2 to output layer: New features are transformed, using a sigmoid activation function.</p></li>
</ul>
<p><span class="math display">\[
\mbox{The final output is: }h_{\theta}(x)=\frac{1}{1+e^{-\theta^\intercal x}}
\]</span></p>
</section>
<section id="logistic-regression-1" class="slide level2">
<h2>Logistic regression (1)</h2>
<p>Recall that, the logistic regression model is:</p>
<p><span class="math display">\[
\log\frac{p(Y=1|x)}{1-p(Y=1|x)}=\theta^\intercal x
\]</span></p>
<p>Isolating <span class="math inline">\(p(Y=1|x)\)</span> and taking logs in both sides:</p>
<p><span class="math display">\[
\frac{p(Y=1|x)}{1-p(Y=1|x)}=e^{\theta^\intercal x}
\]</span></p>
</section>
<section id="logistic-regression-2" class="slide level2">
<h2>Logistic regression (2)</h2>
<p><span class="math display">\[
p(Y=1|x)=\frac{e^{\theta^\intercal x}}{1+e^{\theta^\intercal x}}=\frac{1}{1+e^{-\theta^\intercal x}}
\]</span></p>
<ul>
<li><p>That is: <em>when the activation function of the output node is the sigmoid activation function, the output coincides with a logistic regression on complex features</em></p></li>
<li><p>The output of the ANN. <span class="math inline">\(h_{\theta}(x)\)</span>, estimates <span class="math inline">\(p(Y=1|x)\)</span>.</p></li>
</ul>
</section>
<section id="ann-have-weights-aka-parameters" class="slide level2">
<h2>ANN have weights aka <em>parameters</em></h2>
<ul>
<li>Let <span class="math inline">\(n_l\)</span> denote the number of layers in our network, thus <span class="math inline">\(n_l=3\)</span> in our example.</li>
<li>Layer <span class="math inline">\(L_1\)</span> is input layer, and layer <span class="math inline">\(L_{n_l}=L_3\)</span> the output layer.</li>
<li>Our ANN has parameters <span class="math inline">\(\Theta=(\Theta^{(1)},\Theta^{(2)})\)</span>, where:
<ul>
<li><span class="math inline">\(\theta^{(l)}_{ij}\)</span> denotes weights associated with
<ul>
<li>the connection between unit <span class="math inline">\(j\)</span> in layer <span class="math inline">\(l\)</span> and</li>
<li>unit <span class="math inline">\(i\)</span> in layer <span class="math inline">\(l+1\)</span>.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="back-to-the-example" class="slide level2">
<h2>Back to the example:</h2>
<ul>
<li><p>Thus, in our example, we have:</p>
<ul>
<li><span class="math inline">\(\Theta^{(1)}\in\mathbb{R}^{3\times 4}\)</span>, and</li>
<li><span class="math inline">\(\Theta^{(2)}\in\mathbb{R}^{1\times 4}\)</span>.</li>
</ul></li>
</ul>
<p>Note that bias units don’t have inputs or connections going into them, since they always output the value +1.</p>
</section>
<section id="the-ann-is-defined-by-its-weights" class="slide level2">
<h2>The ANN is defined by its weights</h2>
<ul>
<li><p>Let <span class="math inline">\(s_l\)</span> denote the number of nodes in layer <span class="math inline">\(l\)</span> (not counting the bias unit).</p></li>
<li><p>Now, write <span class="math inline">\(a^{(l)}_i\)</span> to denote the activation (meaning output value) of unit <span class="math inline">\(i\)</span> in layer <span class="math inline">\(l\)</span>.</p>
<ul>
<li>For <span class="math inline">\(l=1\)</span>, <span class="math inline">\(a^{(1)}_i=x_i\)</span> denotes <span class="math inline">\(i\)</span>-th input.</li>
</ul></li>
<li><p>Given a fixed setting of the parameters <span class="math inline">\(\Theta\)</span>, this ANN defines a model <span class="math inline">\(h_{\Theta}(x)\)</span> that outputs a real number.</p></li>
</ul>
</section>
<section id="combining-everything-to-compute" class="slide level2 smaller">
<h2>Combining everything to compute</h2>
<ul>
<li><p>We can now see <em>how these weights are used to produce the output</em>: <span class="math display">\[\begin{eqnarray}
a_1^{(2)}&amp;=&amp;f(\theta_{10}^{(1)}+\theta_{11}^{(1)}x_1+\theta_{12}^{(1)}x_2+\theta_{13}^{(1)}x_3)\\
a_2^{(2)}&amp;=&amp;f(\theta_{20}^{(1)}+\theta_{21}^{(1)}x_1+\theta_{22}^{(1)}x_2+\theta_{23}^{(1)}x_3)\\
a_3^{(2)}&amp;=&amp;f(\theta_{30}^{(1)}+\theta_{31}^{(1)}x_1+\theta_{32}^{(1)}x_2+\theta_{33}^{(1)}x_3)\\
h_{\Theta}(x)&amp;=&amp;a_1^{(3)}=f(\theta_{10}^{(2)}+\theta_{11}^{(2)}a_1^{(2)}+\theta_{12}^{(2)}a_2^{(2)}+\theta_{13}^{(2)}a_3^{(2)})
\end{eqnarray}\]</span></p></li>
<li><p>Now, letting <span class="math inline">\(z_i^{(l)}\)</span> denote the total weighted sum of inputs to unit <span class="math inline">\(i\)</span> in layer <span class="math inline">\(l\)</span>, including the bias term <span class="math display">\[z_i^{(2)}=\theta_{i0}^{(1)}+\theta_{i1}^{(1)}x_1+\theta_{i2}^{(1)}x_2+\theta_{i3}^{(1)}x_3,
\]</span> the output becomes: <span class="math inline">\(a_i^{(l)}=f(z_i^{(l)})\)</span>.</p></li>
</ul>
</section>
<section id="compacting-notation" class="slide level2 smaller">
<h2>Compacting notation</h2>
<ul>
<li><p>Note that this easily lends itself to a more compact notation.</p></li>
<li><p>Activation functions <span class="math inline">\(f(\cdot)\)</span> apply to individual neurons, so it is admisible to write: <span class="math display">\[
  f([z_1,z_2,z_3]) = [f(z_1), f(z_2),f(z_3)],
\]</span></p></li>
<li><p>A more compact notation for previous equations:</p></li>
</ul>
<p><span class="math display">\[
\begin{eqnarray*}
z^{(2)}&amp;=&amp;\Theta^{(1)}x\nonumber\\
a^{(2)}&amp;=&amp;f(z^{(2)})\nonumber\\
z^{(3)}&amp;=&amp;\Theta^{(2)}a^{(2)}\nonumber\\
h_{\Theta}(x)&amp;=&amp;a^{(3)}=f(z^{(3)})\nonumber
\end{eqnarray*}
\]</span></p>
</section>
<section id="compacting-notation-ii" class="slide level2">
<h2>Compacting notation (II)</h2>
<ul>
<li><p>More generally, recalling that we also use <span class="math inline">\(a^{(1)}=x\)</span> to also denote the values from the input layer,</p></li>
<li><p>then given layer <span class="math inline">\(l\)</span>’s activations <span class="math inline">\(a^{(l)}\)</span>, we can compute layer <span class="math inline">\(l+1\)</span>’s activations <span class="math inline">\(a^{(l+1)}\)</span> as:</p></li>
</ul>
<span class="math display">\[\begin{eqnarray}
z^{(l+1)}&amp;=&amp;\Theta^{(l)}a^{(l)}\\
a^{(l+1)}&amp;=&amp;f(z^{(l+1)})
\end{eqnarray}\]</span>
</section>
<section id="matricial-representation-i" class="slide level2 smaller">
<h2>Matricial representation (I)</h2>
<ul>
<li>The output in layer <span class="math inline">\(l+1\)</span>, from layer <span class="math inline">\(l\)</span> can be written as a <em>matrix product</em></li>
</ul>
<p><span class="math display">\[
z^{(l+1)}=
\begin{bmatrix}
z_1^{(l+1)}\\
z_2^{(l+1)}\\
\vdots\\
z_{s_{l+1}}^{(l)}
\end{bmatrix}=
\begin{bmatrix}
\theta_{10}^{(l)}&amp; \theta_{11}^{(l)}&amp;\theta_{12}^{(l)}&amp;...&amp;\theta_{1s_{l}}^{(l)}&amp;\\
\theta_{20}^{(l)}&amp; \theta_{21}^{(l)}&amp;\theta_{22}^{(l)}&amp;...&amp;\theta_{2s_{l}}^{(l)}&amp;\\
\vdots &amp; \vdots&amp; \vdots &amp; \vdots &amp; \vdots\\
\theta_{s_{l+1}0}^{(l)}&amp; \theta_{s_{l+1}1}^{(l)}&amp;\theta_{s_{l+1}2}^{(l)}&amp;...&amp;\theta_{s_{l+1}s_{l}}^{(l)}&amp;\\
\end{bmatrix}
\cdot\begin{bmatrix}
1\\
a_1^{(l)}\\
a_2^{(l)}\\
\vdots\\
a_{s_l}^{(l)}
\end{bmatrix}
\]</span></p>
</section>
<section id="matricial-representation-ii" class="slide level2">
<h2>Matricial representation (II)</h2>
<p>The activation is then:</p>
<p><span class="math display">\[
a^{(l+1)}=
\begin{bmatrix}
a_1^{(l+1)}\\
a_2^{(l+1)}\\
\vdots\\
a_{s_{l+1}}^{(l)}
\end{bmatrix}=f(z^{(l+1)})=\begin{bmatrix}
f(z_1^{(l+1)})\\
f(z_2^{(l+1)})\\
\vdots\\
f(z_{s_{l+1}}^{(l)})
\end{bmatrix}
\]</span></p>
</section>
<section id="forward-propagation" class="slide level2">
<h2>Forward propagation</h2>
<ul>
<li><p>By organizing our parameters in matrices</p></li>
<li><p>and using matrix-vector operations,</p></li>
<li><p>we can take advantage of fast linear algebra routines to</p></li>
<li><p>quickly perform calculations in our network.</p></li>
<li><p>This process is called <em>forward propagation</em>.</p></li>
</ul>
</section>
<section id="multiple-architectures-for-ann" class="slide level2">
<h2>Multiple architectures for ANN</h2>
<ul>
<li><p>We have so far focused on a single hidden layer neural network of the example</p></li>
<li><p>One can build neural networks with many distinct architectures (meaning patterns of connectivity between neurons), including ones with multiple hidden layers.</p></li>
<li><p>See <a href="https://www.asimovinstitute.org/neural-network-zoo/">here the Neural Network Zoo</a>.</p></li>
</ul>
</section>
<section id="multiple-layer-dense-networks" class="slide level2">
<h2>Multiple layer dense Networks</h2>
<ul>
<li>Most common choice is a <span class="math inline">\(n_l\)</span>-layered network:
<ul>
<li>layer 1 is the input layer,</li>
<li>layer <span class="math inline">\(n_l\)</span> is the output layer,</li>
<li>and each layer <span class="math inline">\(l\)</span> is densely connected to layer <span class="math inline">\(l+1\)</span>.</li>
</ul></li>
<li>In this setting, to compute the output of the network, we can compute all the activations in layer <span class="math inline">\(L_2\)</span>, then layer <span class="math inline">\(L_3\)</span>, and so on, up to layer <span class="math inline">\(L_{nl}\)</span>, using equations seen previously.</li>
</ul>
</section>
<section id="feed-forward-neural-networks-ffnn" class="slide level2">
<h2>Feed Forward neural networks (FFNN)</h2>
<ul>
<li>The type of NN described is called feed-forward <em>neural network (FFNN)</em>, since
<ul>
<li>All computations are done by Forward propagation</li>
<li>The connectivity graph does not have any directed loops or cycles.</li>
</ul></li>
</ul>
</section>
<section id="a-loss-function-for-optimization" class="slide level2">
<h2>A loss function for optimization</h2>
<ul>
<li><p>In order to estimate the weights we will aim at minimizing an appropriate loss function.</p></li>
<li><p>A first idea may be to use <em>squared error loss</em> <span class="math display">\[
l(h_\theta(x),y)=(y-\frac{1}{1+e^{-\theta^\intercal x}})^2
\]</span></p></li>
<li><p>However it happens to be that <a href="https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c"><em>this is is not a convex problem</em></a> which means that MSE is not appropriate.</p></li>
</ul>
</section>
<section id="cross-entropy-loss-function" class="slide level2">
<h2>Cross-entropy loss function</h2>
<ul>
<li>Alternatively, we use the <em>binary cross-entropy loss function</em> : <span class="math display">\[
l(h_\theta(x),y)=\big{\{}\begin{array}{ll}
-\log h_\theta(x) &amp; \textrm{if }y=1\\
-\log(1-h_\theta(x))&amp; \textrm{if }y=0
\end{array}
\]</span></li>
<li>It can be written compactly as:</li>
</ul>
<p><span class="math display">\[
l(h_\theta(x),y)=-y\log h_\theta(x) - (1-y)\log(1-h_\theta(x))
\]</span></p>
</section>
<section id="a-convex-cost-function" class="slide level2">
<h2>A convex cost function</h2>
<ul>
<li>Using cross-entropy loss, the cost function is of the form: <span class="math display">\[\begin{eqnarray*}
J(\theta)=-\frac{1}{n}\big[\sum_{i=1}^n&amp;&amp;(y^{(i)}\log h_\theta(x^{(i)})+\\ &amp;&amp;(1-y^{(i)})\log(1-h_\theta(x^{(i)}))\big]
\end{eqnarray*}\]</span></li>
<li>This is a convex optimization problem.</li>
</ul>
</section>
<section id="a-regularized-cost-function" class="slide level2">
<h2>A regularized cost function</h2>
<ul>
<li>Better to work with a <em>regularized version</em> of the cost function (we don’t regularize the bias units)</li>
</ul>
<span class="math display">\[\begin{eqnarray*}
J(\Theta)&amp;=&amp;-\frac{1}{n}\big[\sum_{i=1}^n \sum_{k=1}^K y_k^{(i)}\log( h_\theta(x^{(i)}))_k\\
&amp;+&amp;(1-y_k^{(i)})\log(1-(h_\theta(x^{(i)}))_k)\big]\\
&amp;+&amp;\lambda\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}
(\theta_{ji}^{(l)})^2
\end{eqnarray*}\]</span>
</section>
<section id="optimization-with-gradient-descent" class="slide level2">
<h2>Optimization with gradient descent</h2>
<ul>
<li>In ANN we do not aim at finding estimating equations (like <em>likekihood equations</em>) whose solution will solve the optimization problem</li>
<li>Instead we use iterative procedures, that
<ul>
<li>Are much faster</li>
<li>Yield results as near the optimum as required.</li>
</ul></li>
<li>The (first) option of choice is the gradient descent method.</li>
</ul>
</section>
<section id="how-gradient-descent-works-i" class="slide level2">
<h2>How gradient descent works (I)</h2>
<!-- - The method proceeds iteratively, computing a sequence of vectors in $\mathbb{R}^p$  -->
<!-- - with the aim of converging to a vector that minimizes the cost function.  -->
<ul>
<li>Suppose that our current vector is <span class="math inline">\(\theta\)</span>.</li>
<li>How should we choose a perturbation, <span class="math inline">\(\Delta\theta\)</span>, so that the next vector, <span class="math inline">\(\theta+\Delta\theta\)</span>, represents an improvement?</li>
<li>If <span class="math inline">\(\Delta\theta\)</span> is small, then ignoring terms of order <span class="math inline">\(||\Delta\theta||^2\)</span>, a Taylor series expansion gives <span class="math display">\[
J(\theta+\Delta\theta)\approx J(\theta)+\sum_{i=1}^p\frac{\partial J(\theta)}{\partial\theta_i}\Delta\theta_i
\]</span></li>
</ul>
<!-- Here -->
<!-- $\frac{\partial J(\theta)}{\partial\theta_i}$  -->
<!-- denotes the -->
<!-- partial derivative of the cost function with respect to the $i$-th -->
<!-- weight.  -->
</section>
<section id="how-gradient-descent-works-ii" class="slide level2">
<h2>How gradient descent works (II)</h2>
<ul>
<li><p>Let <span class="math inline">\(\nabla J(\theta)\in\mathbb{R}^p\)</span> be the vector of partial derivatives, aka the gradient: <span class="math display">\[\begin{equation}\label{g1}
\nabla J(\theta)=\big(\frac{\partial J(\theta)}{\partial\theta_1},...,\frac{\partial J(\theta)}{\partial\theta_p}\big)^\intercal, \mbox{then:}
\end{equation}\]</span> <span class="math display">\[\begin{equation}\label{g2}
J(\theta+\Delta\theta)\approx J(\theta)+\nabla J(\theta)^\intercal\Delta\theta
\end{equation}\]</span></p></li>
<li><p>Our aim is to reduce the value of the cost function.</p></li>
<li><p>It seems reasonable to choose <span class="math inline">\(\Delta\theta\)</span> (a <em>direction</em>) to make <span class="math inline">\(\nabla J(\theta)^\intercal\Delta\theta\)</span> as negative as possible.</p></li>
</ul>
</section>
<section id="how-gradient-descent-works-iii" class="slide level2">
<h2>How gradient descent works (III)</h2>
<ul>
<li>This can be addressed via the Cauchy-Schwarz inequality:
<ul>
<li>For any <span class="math inline">\(f,g\in\mathbb{R}^p\)</span>, we have <span class="math inline">\(|f^\intercal g|\leq ||f||\cdot ||g||\)</span>.</li>
<li>Moreover, the two sides are equal if and only if <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are linearly dependent (meaning they are parallel).</li>
</ul></li>
</ul>
</section>
<section id="how-gradient-descent-works-iv" class="slide level2">
<h2>How gradient descent works (IV)</h2>
<ul>
<li><p>So *the most negative that <span class="math inline">\(f^\intercal g\)</span> can be is <span class="math inline">\(-||f||\cdot||g||\)</span>,</p></li>
<li><p>This happens when <span class="math inline">\(f=-g\)</span>.</p></li>
<li><p>Hence *we should choose <span class="math inline">\(\Delta\theta\)</span> to lie in the direction of <span class="math inline">\(-\nabla J(\theta)\)</span>.</p></li>
<li><p>Keeping in mind that this approximation is relevant only for small <span class="math inline">\(\Delta\theta\)</span>, we will limit ourselves to a small step in that direction.</p></li>
</ul>
</section>
<section id="how-gradient-descent-works-v" class="slide level2">
<h2>How gradient descent works (V)</h2>
<ul>
<li><p>This leads to the update <span class="math display">\[\begin{equation}\label{g3}
\theta \rightarrow \theta-\eta\nabla J(\theta)
\end{equation}\]</span></p></li>
<li><p><span class="math inline">\(\eta\)</span> is small step size known as the <em>learning rate</em>.</p></li>
<li><p>This equation defines the steepest descent method.</p></li>
<li><p>We choose an initial vector and iterate</p>
<ul>
<li>until some stopping criterion has been met,</li>
<li>or until the number of iterations has exceeded the computational budget.</li>
</ul></li>
</ul>
</section>
<section id="the-gradient-descent-algorithm" class="slide level2">
<h2>The gradient descent algorithm</h2>
<ul>
<li>Repeat:</li>
</ul>
<p><span class="math display">\[
\theta_j=\theta_j-\eta\frac{\partial}{\partial\theta_j}J(\theta)
\]</span></p>
<p><span class="math display">\[
\qquad \textrm{and simultaneously update all }\qquad \theta_j
\]</span></p>
<p><span class="math inline">\(\eta\in (0,1]\)</span> denotes the learning parameter.</p>
</section>
<section id="gradient-descent-computes-derivatives" class="slide level2">
<h2>Gradient descent computes derivatives</h2>
<ul>
<li>We aim to minimise the cost function</li>
</ul>
<p><span class="math display">\[
\underset{\theta}{\textrm{min }}J(\theta)
\]</span></p>
<ul>
<li>In order to use gradient descent, we need to compute <span class="math inline">\(J(\theta)\)</span> and the partial derivatives: <span class="math display">\[
\frac{\partial}{\partial\theta_j}J(\theta)
\]</span></li>
</ul>
</section>
<section id="other-requirements-for-gradient-descent" class="slide level2">
<h2>Other requirements for gradient descent</h2>
<ul>
<li>The input data have to be normalized to have approximately the same range.</li>
<li>Biases can be initialized to 0, but they <em>cannot be initialized with the same values, otherwise, all the neurons of a hidden layer would have the same behavior</em>.</li>
<li>Initial parameters need to break symmetry between different units so weights are usually initialized at random:</li>
</ul>
</section>
<section id="weights-initialization" class="slide level2">
<h2>Weights initialization</h2>
<ul>
<li>We assume values <span class="math inline">\(\theta_{ij}^{(l)}\)</span> to be
<ul>
<li>i.i.d. Uniform on <span class="math inline">\([-c,c]\)</span></li>
<li>with possibly <span class="math inline">\(c= 1/\sqrt{N_l}\)</span> where <span class="math inline">\(N_l\)</span> is the size of the hidden layer <span class="math inline">\(l\)</span>.</li>
</ul></li>
<li>We also sometimes initialize the weights with a normal distribution <span class="math inline">\(N(0,0.01)\)</span>.</li>
</ul>
</section>
<section id="gradient-descent-drawbacks" class="slide level2">
<h2>Gradient descent drawbacks</h2>
<ul>
<li>When we have a large number of parameters and a large number of training points, computing the gradient vector (<span class="math inline">\(\ref{g1}\)</span>) at every iteration of the steepest descent method can be time consuming.</li>
<li>It is mainly due to that we have <em>to sum across all training points</em>.</li>
<li>This becomes prohibitively expensive when we have Big Data.</li>
</ul>
</section>
<section id="stochastic-gradient" class="slide level2 smaller">
<h2>Stochastic Gradient</h2>
<ul>
<li><p>A much cheaper alternative is to replace the mean of the individual gradients over all training points</p></li>
<li><p>by the gradient at a single, randomly chosen, training point.</p></li>
<li><p>This leads to the simplest form of the <em>stochastic gradient method</em>.</p></li>
<li><p>Choose an integer <span class="math inline">\(i\)</span> uniformly at random from <span class="math inline">\(\{1,...,n\}\)</span> and update <span class="math display">\[\begin{equation}\label{g4}
\theta_j=\theta_j-\eta\frac{\partial}{\partial\theta_j}J(\theta;x^{(i)})
\end{equation}\]</span></p></li>
<li><p>Notice we have included <span class="math inline">\(x^{(i)}\)</span> in the notation of <span class="math inline">\(J(\theta;x^{(i)})\)</span> to remark the dependence.</p></li>
</ul>
</section>
<section id="rationale-for-sgd" class="slide level2">
<h2>Rationale for SGD</h2>
<p>-At each step, the stochastic gradient method uses one randomly chosen training point to represent the full training set.</p>
<ul>
<li><p>As the iteration proceeds, the method sees more training points.</p></li>
<li><p>So <em>there is some hope</em> that this dramatic reduction in cost-per-iteration will be worthwhile overall.</p></li>
<li><p>Note that, even for very small <span class="math inline">\(\eta\)</span>, the update (<span class="math inline">\(\ref{g4}\)</span>) is not guaranteed to reduce the overall cost function we have traded the mean for a single sample.</p></li>
<li><p>Hence, although the phrase stochastic gradient descent is widely used, we prefer to use <strong>stochastic gradient</strong>.</p></li>
</ul>
</section>
<section id="sgd-variants" class="slide level2">
<h2>SGD variants</h2>
<ul>
<li>The version of the stochastic gradient method that we introduced in (<span class="math inline">\(\ref{g4}\)</span>) is the simplest from a large range of possibilities.</li>
<li>In particular, the index <span class="math inline">\(i\)</span> in (<span class="math inline">\(\ref{g4}\)</span>) was chosen by sampling with replacement after using a training point, it is returned to the training set and is just as likely as any other point to be chosen at the next step.</li>
<li>An alternative is to sample without replacement; that is, to cycle through each of the <span class="math inline">\(n\)</span> training points in a random order.</li>
<li>Performing <span class="math inline">\(n\)</span> steps in this manner, referred to as completing an epoch, may be summarized as follows:</li>
</ul>
</section>
<section id="sgd-variants-3" class="slide level2">
<h2>SGD variants (3)</h2>
<ul>
<li>If we regard the stochastic gradient method as approximating the mean over all training points by a single sample, then</li>
<li>It is natural to consider a compromise where we use a small sample average. For some <span class="math inline">\(m&lt;&lt;n\)</span> we could take steps of the following form.</li>
</ul>
<ul>
<li>In this iteration, the set <span class="math inline">\(\{x^{(k_i)}\}_{i=1}^m\)</span> is known as a mini-batch.</li>
</ul>
</section>
<section id="improving-sgd" class="slide level2">
<h2>Improving SGD</h2>
<ul>
<li>Because the stochastic gradient method is usually implemented within the context of a very large scale computation, algorithmic choices such as mini-batch size and the form of randomization are often driven by the requirements of high performance computing architectures.</li>
<li>Also, it is, of course, possible to vary these choices, along with others, such as the learning rate, dynamically as the training progresses in an attempt to accelerate convergence.</li>
</ul>
</section>
<section id="back-propagation" class="slide level2">
<h2>Back propagation</h2>
<ul>
<li>Back-propagation is the algorithm used to compute the gradients of the network.</li>
<li>This procedure was developed by several authors in the decade of the 60’s but is Paul J. Werbos, (1974) in his thesis when demonstrates the use of this algorithm for ANN. - Years later, (David, E.</li>
</ul>
<ol start="1986" type="1">
<li>presents the modern way to apply this technique to ANN, and sets the basis of the algorithm in use today.</li>
</ol>
</section>
<section id="the-delta-rule" class="slide level2">
<h2>The delta rule</h2>
<ul>
<li><p>In this paper, the authors presents a new method capable to change the predictions towards a desired output, they called it the delta rule.</p></li>
<li><p>This rule consist in compute the total error for the network and check how the error changes when certain elements from the network changes its value.</p></li>
<li><p>These changes are computed by differentiating the cost function with regard to each element in the network<br>
</p></li>
<li><p>Which would give us a measure of how much each element is contributing to the total error of the network,</p></li>
<li><p>This is, computing the gradient of the cost function we can know how the total error changes with regard to each element, and therefore apply the delta rule.</p></li>
</ul>
</section>
<section id="applying-the-chain-rule" class="slide level2">
<h2>Applying the chain rule</h2>
<ul>
<li>The cost function is an intricate composed function which contains the weights of all layers,</li>
<li>the problem now is that the computations of this gradients are not straightforward as in a simple function,</li>
<li>A node from a layer is the result of the composition of all the nodes from previous layers.</li>
<li>To overcome it, Back-propagation uses the chain rule of differential calculus to compute the gradients of each element in the neural network,</li>
</ul>
<p>-It contains two main phases referred to as the forward phase and backward phase:</p>
</section>
<section id="back-propagation-forward-phase" class="slide level2">
<h2>Back-propagation: <strong>Forward Phase</strong>:</h2>
<ul>
<li>The inputs for a data example are fed into the FNN.</li>
<li>These inputs will be propagated through the network for all the neurons in all the layers using the current set of weights, to finally compute the final output.</li>
</ul>
</section>
<section id="back-propagation-backward-phase" class="slide level2">
<h2>Back-propagation: <strong>Backward Phase</strong>:</h2>
<ul>
<li>Once the final output and the cost function are computed, we need to compute the gradients for all the weights in all the layers in the FNN to update them in order to reach the minimum.</li>
<li>To compute the gradients the chain rule is used, is a backwards a process from output to input,</li>
<li>Therefore we will start from the output node, compute all the gradients of the previous layer, and so on until we reach the input layer.</li>
</ul>
</section></section>
<section id="references-and-resources" class="title-slide slide level1 center">
<h1>References and Resources</h1>
<div class="footer footer-default">

</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="Introduction_to_Deep_Learning-Slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"width":"half","numbers":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'slow',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>