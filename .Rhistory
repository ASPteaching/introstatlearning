cv.mydataset
# Chunk 24
par(mfrow=c(1,2))
plot(cv.mydataset$size,cv.mydataset$dev,type="b")
plot(cv.mydataset$k,cv.mydataset$dev,type="b")
par(mfrow=c(1,1))
# Chunk 25: fig.DT2
prune.mydataset=prune.misclass(tree.mydataset,
best=cv.mydataset$size[which.min(cv.mydataset$dev)])
plot(prune.mydataset)
text(prune.mydataset,pretty=0)
# Chunk 26
tree.pred=predict(prune.mydataset,mydataset.test,type="class")
res <- table(tree.pred,High.test)
res
accrcy <- sum(diag(res)/sum(res))
# Chunk 27: fig.DT3
prune.mydataset=prune.misclass(tree.mydataset,
best = cv.mydataset$size[1])
plot(prune.mydataset)
text(prune.mydataset, pretty=0)
# Chunk 28
tree.pred=predict(prune.mydataset, mydataset.test, type="class")
res <- table(tree.pred, High.test)
res
accrcy <- sum(diag(res)/sum(res))
# Chunk 29
library(MASS)
data("Boston")
datos <- Boston
head(datos, 3)
# Chunk 30
color <- adjustcolor("forestgreen", alpha.f = 0.5)
ps <- function(x, y, ...) {  # custom panel function
panel.smooth(x, y, col = color, col.smooth = "black",
cex = 0.7, lwd = 2)
}
pairs(datos[,c(1:6,14)], cex = 0.7, upper.panel = ps, col = color)
pairs(datos[,c(7:14)], cex = 0.7, upper.panel = ps, col = color)
# Chunk 31
set.seed(123)
train <- sample(1:nrow(datos), size = nrow(datos)/2)
datos_train <- datos[train,]
datos_test  <- datos[-train,]
# Chunk 32
set.seed(123)
arbol_regresion <- tree::tree(
formula = medv ~ .,
data    = datos_train,
split   = "deviance",
mincut  = 20,
minsize = 50
)
summary(arbol_regresion)
# Chunk 33
par(mar = c(1,1,1,1))
plot(x = arbol_regresion, type = "proportional")
text(x = arbol_regresion, splits = TRUE, pretty = 0, cex = 0.8, col = "firebrick")
# Chunk 34
arbol_regresion <- tree::tree(
formula = medv ~ .,
data    = datos_train,
split   = "deviance",
mincut  = 1,
minsize = 2,
mindev  = 0
)
# Optimization
set.seed(123)
cv_arbol <- tree::cv.tree(arbol_regresion, K = 5)
# Chunk 35
size_optimo <- rev(cv_arbol$size)[which.min(rev(cv_arbol$dev))]
paste("Optimal size obtained is:", size_optimo)
# Chunk 36
library(ggplot2)
library(ggpubr)
resultados_cv <- data.frame(
n_nodes  = cv_arbol$size,
deviance = cv_arbol$dev,
alpha    = cv_arbol$k
)
p1 <- ggplot(data = resultados_cv, aes(x = n_nodes, y = deviance)) +
geom_line() +
geom_point() +
geom_vline(xintercept = size_optimo, color = "red") +
labs(title = "Error vs tree size") +
theme_bw()
p2 <- ggplot(data = resultados_cv, aes(x = alpha, y = deviance)) +
geom_line() +
geom_point() +
labs(title = "Error vs penalization (alpha)") +
theme_bw()
ggarrange(p1, p2)
# Chunk 37
arbol_final <- tree::prune.tree(
tree = arbol_regresion,
best = size_optimo
)
par(mar = c(1,1,1,1))
plot(x = arbol_final, type = "proportional")
text(x = arbol_final, splits = TRUE, pretty = 0, cex = 0.8, col = "firebrick")
# Chunk 38
predicciones <- predict(arbol_regresion, newdata = datos_test)
test_rmse    <- sqrt(mean((predicciones - datos_test$medv)^2))
paste("Error de test (rmse) del árbol inicial:", round(test_rmse,2))
# Chunk 39
predicciones_finales <- predict(arbol_final, newdata = datos_test)
test_rmse    <- sqrt(mean((predicciones - datos_test$medv)^2))
paste("Error de test (rmse) del árbol final:", round(test_rmse,2))
# Chunk 40
if(!require(AmesHousing))
install.packages("AmesHousing", dep=TRUE)
ames <- AmesHousing::make_ames()
# Chunk 41
if(!require(rsample))
install.packages("rsample", dep=TRUE)
# Stratified sampling with the rsample package
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
# Chunk 42
require(rpart)
ames_dt1 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train
# method  = "anova"
)
# Chunk 43
require(rpart.plot)
rpart.plot(ames_dt1, cex=0.5)
# Chunk 44
printcp(ames_dt1)
# Chunk 45
plotcp(ames_dt1)
# Chunk 46
if(!require(vip))
install.packages("vip", dep=TRUE)
require(vip)
## ? vip
vip(ames_dt1, num_features = 40, bar = FALSE)
# Chunk 47
ames_dt2 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
vip2<- vip(ames_dt1, num_features = 40, bar = FALSE)
plot(vip2)
vip2<- vip(ames_dt2, num_features = 40, bar = FALSE)
plot(vip2)
? prune
plotcp(ames_dt1)
ames_dt2 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
# make bootstrapping reproducible
set.seed(123)
# train bagged model
system.time(
ames_bag1 <- bagging(
formula = Sale_Price ~ .,
data = ames_train,
nbagg = 100,
coob = TRUE,
control = rpart.control(minsplit = 2, cp = 0)
)
)
# If the package is not installed then it will be installed
if(!require("knitr")) install.packages("knitr")
if(!require("tree")) install.packages("tree")
if(!require("ISLR")) install.packages("ISLR")
if(!require("rpart.plot")) install.packages("rpart.plot")
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
library(doParallel)  # for parallel backend to foreach
library(foreach)     # for parallel processing with for loops
# Modeling packages
library(caret)       # for general model fitting
library(rpart)       # for fitting decision trees
library(ipred)       # for fitting bagged decision trees
if(!require(AmesHousing))
install.packages("AmesHousing", dep=TRUE)
ames <- AmesHousing::make_ames()
if(!require(rsample))
install.packages("rsample", dep=TRUE)
# Stratified sampling with the rsample package
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
# train bagged model
system.time(
ames_bag1 <- bagging(
formula = Sale_Price ~ .,
data = ames_train,
nbagg = 100,
coob = TRUE,
control = rpart.control(minsplit = 2, cp = 0)
)
)
show(ames_bag1)
# Prepare "clean" dataset from raw data
ames <- AmesHousing::make_ames()
# Split in test/training
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
system.time()
ames_bag1 <- ipred::bagging(
formula = Sale_Price ~ .,
data = ames_train,
nbagg = 100,  coob = TRUE,
control = rpart.control(minsplit = 2, cp = 0)
))
# Chunk 1
knitr::include_graphics("images/fromRealWorld2BootstrapWorld.png")
# Chunk 2
knitr::include_graphics("images/oobErrorEstimation.jpg")
# Chunk 3
knitr::include_graphics("images/oobErrorEstimation.png")
# Chunk 4
# Prepare "clean" dataset from raw data
ames <- AmesHousing::make_ames()
# Split in test/training
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
vip::vip(ames_bag1, num_features = 40, bar = FALSE)
# If the package is not installed then it will be installed
if(!require("knitr")) install.packages("knitr")
if(!require("tree")) install.packages("tree")
if(!require("ISLR")) install.packages("ISLR")
if(!require("rpart.plot")) install.packages("rpart.plot")
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
library(doParallel)  # for parallel backend to foreach
library(foreach)     # for parallel processing with for loops
# Modeling packages
library(caret)       # for general model fitting
library(rpart)       # for fitting decision trees
library(ipred)       # for fitting bagged decision trees
if(!require(AmesHousing))
install.packages("AmesHousing", dep=TRUE)
ames <- AmesHousing::make_ames()
if(!require(rsample))
install.packages("rsample", dep=TRUE)
# Stratified sampling with the rsample package
set.seed(123)
split <- rsample::initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- rsample::training(split)
ames_test   <- rsample::testing(split)
# make bootstrapping reproducible
set.seed(123)
# train bagged model
system.time(
ames_bag1 <- bagging(
formula = Sale_Price ~ .,
data = ames_train,
nbagg = 100,
coob = TRUE,
control = rpart.control(minsplit = 2, cp = 0)
)
)
show(ames_bag1)
knitr::include_graphics("images/baggingRSME.png")
vip::vip(ames_bag1, num_features = 40, bar = FALSE)
ames_bag2 <- train(
Sale_Price ~ .,
data = ames_train,
method = "treebag",
trControl = trainControl(method = "cv", number = 10),
nbagg = 200,
control = rpart.control(minsplit = 2, cp = 0)
)
vip::vip(ames_bag2)
vip::vip(ames_bag1)
pred.imp <- varImp(ames_bag1)
pred.imp
plot(pred.imp)
barplot(pred.imp$Overall,
names.arg = row.names(pred.imp),
horiz = TRUE)
barplot(sort(pred.imp$Overall)[1:40],
names.arg = row.names(pred.imp),
horiz = TRUE)
names(pred.imp)
pred.imp
class(pred.imp)
pred.imp <- varImp(ames_bag1) %>% arrange ()
pred.imp
pred.imp <- varImp(ames_bag1) %>% arrange () %>% filter(1:40)
pred.imp <- varImp(ames_bag1) %>%
arrange () %>%
slice(1:40)
barplot(pred.imp$Overall,
names.arg = row.names(pred.imp),
horiz = TRUE)
pred.imp <- varImp(ames_bag1) %>%
arrange (Overall) %>%
slice(1:40)
barplot(pred.imp$Overall,
names.arg = row.names(pred.imp),
horiz = TRUE)
barplot(pred.imp$Overall,
names = row.names(pred.imp),
horiz = TRUE)
View(pred.imp)
p <- ggplot(pred.imp, aes(x = Overall))+ coord_flip()
p
p <- ggplot(pred.imp, aes(x = Overall))+
geom_col(aes(fill = Overall), width = 0.7)+
coord_flip()
p
barplot(pred.imp$Overall)
barplot(pred.imp$Overall,
labels=row.names(pred.imp))
barplot(pred.imp$Overall,
labels=row.names(pred.imp), cex.axis=o.5)
barplot(pred.imp$Overall,
labels=row.names(pred.imp), cex.axis=0.5)
? barplot
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.axis=0.5)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.axis=0.5,
horiz = TRUE)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex=0.5,
horiz = TRUE)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.5,
horiz = TRUE)
p
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.3,
horiz = TRUE)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.3,
horiz = TRUE)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.3,
horiz = TRUE)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.1,
horiz = TRUE)
head(pred.imp, n=10)
pred.imp <- varImp(ames_bag1) %>%
arrange (Overall) %>%
slice(1:40)
head(pred.imp, n=10)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.1,
horiz = TRUE)
? arrange
pred.imp <- varImp(ames_bag1) %>%
arrange (desc(Overall)) %>%
slice(1:40)
barplot(pred.imp$Overall,
names.arg=row.names(pred.imp), cex.names=0.1,
horiz = TRUE)
head(pred.imp)
pred.imp <- varImp(ames_bag1)
pred.imp<- pred.imp/sum(pred.imp)*100 %>%
arrange (desc(Overall)) %>%
slice(1:40)
pred.imp$Overall<- pred.imp$Overall/sum(pred.imp$Overall)*100
varImp <pred.imp %>%  arrange (desc(Overall)) %>%
slice(1:40)
varImp <- pred.imp %>%  arrange (desc(Overall)) %>%
slice(1:40)
barplot(varImp$Overall,
names.arg=row.names(pred.imp), cex.names=0.1,
horiz = TRUE)
varImpt
barplot(varImpt$Overall,
names.arg=row.names(varImpt), cex.names=0.1,
horiz = TRUE)
varImpt <- pred.imp %>%  arrange (desc(Overall)) %>%
slice(1:40)
barplot(varImpt$Overall,
names.arg=row.names(varImpt), cex.names=0.1,
horiz = TRUE)
head(varImpt)
head(varImpt, n=10)
barplot(varImpt$Overall,
names.arg=row.names(varImpt), cex.names=0.1,
horiz = TRUE)
varImpt <- pred.imp %>%  arrange (desc(Overall)) %>%
slice(1:40)
head(varImpt, n=10)
? trinControl
? trainControl
ames_bag2 <- train(
Sale_Price ~ .,
data = ames_train,
method = "treebag",
trControl = trainControl(method = "oob"),
nbagg = 100,
control = rpart.control(minsplit = 2, cp = 0)
)
system.time(
ames_bag2 <- train(
Sale_Price ~ .,
data = ames_train,
method = "treebag",
trControl = trainControl(method = "oob"),
nbagg = 100,
keepX=TRUE,
control = rpart.control(minsplit = 2, cp = 0)
)
)
vip::vip(ames_bag2, num_features = 40, bar = FALSE)
vip::vip(ames_bag2, num_features = 40)
save(ames_bag2, file="ames_bag2.Rda")
file.exists("ames_bag2.Rda")
load(file="ames_bag2.Rda")
load(file="ames_bag2.Rda")
dev.off()
vip::vip(ames_bag2, num_features = 40)
BiocManager::install(c("affy", "genefilter"))
library(ALL)
if(!require(ALL)) BiocManager::install("ALL")
library(affy)
library(genefilter)
library(ALL)
data(ALL)
library(genefilter);
e.mat <- 2^(exprs(ALL)[,c(81:110)])
ffun <- filterfun(pOverA(0.20,100))
t.fil <- genefilter(e.mat,ffun)
small.eset <- log2(e.mat[t.fil,])
dim(small.eset)
pData(small.eset)
library(Biobase)
pData(small.eset)
colnames(small.eset)
pData(ALL)
group <- c(rep('B',15),rep('T',15))
dim(small.eset)
colnames(small.eset)
pData(ALL)
pData(ALL)[81:110]
pData(ALL)[81:110,]
pData(ALL)[81:110,1:5]
if (!require(randomForest)) install.packages("randomForest", dep=TRUE)
library(randomForest)
set.seed(1234)
system.time(
rf <- randomForest(x=t(small.eset),
y=as.factor(group),
ntree=10000)
)
rf
imp.temp <- abs(rf$importance[,])
t <- order(imp.temp,decreasing=TRUE) plot(c(1:nrow(small.eset)),imp.temp[t],log='x',cex.main=1.5,    xlab='gene rank',ylab='variable importance',cex.lab=1.5,    pch=16,main='ALL subset results')
t <- order(imp.temp,decreasing=TRUE)
plot(c(1:nrow(small.eset)),imp.temp[t],log='x',cex.main=1.5,    xlab='gene rank',ylab='variable importance',cex.lab=1.5,    pch=16,main='ALL subset results')
gn.imp <- names(imp.temp)[t]
gn.25 <- gn.imp[1:25]
gn.25
if(!require(affy)) BiocManager::install("hgu95av2.db")
if(!require(AnnotationDbi)) BiocManager::install("AnnotationDbi")
geneAnots <- AnnotationDbi::select(hgu95av2.db, gn.25,
c("SYMBOL", "ENTREZID", "GENENAME"))
if(!require(affy)) BiocManager::install("hgu95av2.db")
if(!require(hgu95av2.db)) BiocManager::install("hgu95av2.db")
if(!require(AnnotationDbi)) BiocManager::install("AnnotationDbi")
geneAnots <- AnnotationDbi::select(hgu95av2.db, gn.25,
c("SYMBOL", "ENTREZID", "GENENAME"))
library(hgu95av2.db)
geneAnots <- AnnotationDbi::select(hgu95av2.db, gn.25,
c("SYMBOL", "ENTREZID", "GENENAME"))
head(geneAnots)
head(geneAnots, n=10)
head(geneAnots, n=20)
head(geneAnots, n=25)
geneAnots <- AnnotationDbi::select(hgu95av2.db, gn.25,
c("SYMBOL", "GENENAME"))
head(geneAnots, n=25)
t <- is.element(rownames(small.eset),gn.25)
sig.eset <- small.eset[t,]
# matrix of expression values, not necessarily in order
library(RColorBrewer)
hmcol <- colorRampPalette(brewer.pal(11,"PuOr"))(256)
colnames(sig.eset) <- group
# This will label the heatmap columns
csc <- rep(hmcol[50],30)
csc[group=='T'] <- hmcol[200]
# column side color will be purple for T and orange for B
heatmap(sig.eset,scale="row", col=hmcol,ColSideColors=csc)
sig.eset
varImpPlot(rf, n.var=25, main='ALL Subset Results')
if (!require(neuralnet))
install.packages("neuralnet", dep=TRUE)
if (!require(caret))
install.packages("caret", dep=TRUE)
purl("Introduction_to_Deep_Learning.qmd")
knitr::purl("Introduction_to_Deep_Learning.qmd")
